# SignVisorðŸ‘“ðŸ¤Ÿ

Smart Glass Interface for Real-Time American Sign Language (ASL) Translation

A wearable AI system that translates ASL into text in real-time using computer vision and deep learning.
# About the Project
SignVisor is an AI-powered wearable system designed to bridge the communication gap between the Deaf or Mute and non-sign language users. It uses a smart glass interface with a camera and real-time ASL gesture recognition to convert hand signs into readable text.

# Features
- Live ASL Gesture Detection using OpenCV and Mediapipe

- Dotted & Line Hand Structure for better gesture recognition

- 26 Alphabet ASL Classification

- Visual Feedback of hand landmarks and predictions

- Custom-trained Model for high accuracy on ASL data

- Web Integration (planned) for browser-based real-time translation

# Tech Stack

- Programming Language: Python

- Libraries & Frameworks: OpenCV, MediaPipe, NumPy, scikit-learn, TensorFlow/PyTorch
- Hardware: Webcam or smart glasses with camera (for real-time)
